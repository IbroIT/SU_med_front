#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –≤ —Ñ–∞–π–ª–∞—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤.
–î—É–±–ª–∏–∫–∞—Ç—ã - —ç—Ç–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–∞–∑–¥–µ–ª—ã (–≥–ª–∞–≤—ã) —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –∫–ª—é—á–∞–º–∏,
–∞ –ù–ï –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–∞—Ö.
"""

import json
import os
from pathlib import Path
from collections import defaultdict, Counter
import sys

def find_duplicate_sections(json_data, path=""):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ä–∞–∑–¥–µ–ª—ã –≤ JSON –¥–∞–Ω–Ω—ã—Ö.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å: {section_name: [(path, content), (path, content), ...]}
    """
    duplicates = defaultdict(list)
    section_contents = defaultdict(list)
    
    if isinstance(json_data, dict):
        for key, value in json_data.items():
            current_path = f"{path}.{key}" if path else key
            
            if isinstance(value, dict):
                # –≠—Ç–æ —Ä–∞–∑–¥–µ–ª - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                section_contents[key].append((current_path, value))
                
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
                nested_duplicates = find_duplicate_sections(value, current_path)
                for dup_key, dup_list in nested_duplicates.items():
                    duplicates[dup_key].extend(dup_list)
    
    # –ù–∞—Ö–æ–¥–∏–º —Ä–∞–∑–¥–µ–ª—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –∏–º–µ–Ω–∞–º–∏
    for section_name, occurrences in section_contents.items():
        if len(occurrences) > 1:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç—ã (–æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ)
            contents = [occ[1] for occ in occurrences]
            if len(set(json.dumps(content, sort_keys=True) for content in contents)) > 1:
                # –†–∞–∑–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ - —ç—Ç–æ –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
                continue
            elif len(set(json.dumps(content, sort_keys=True) for content in contents)) == 1:
                # –û–¥–∏–Ω–∞–∫–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ - —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç—ã
                duplicates[section_name] = occurrences
    
    return duplicates

def analyze_file(file_path):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""
    print(f"\nüìÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return None
    
    # –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ä–∞–∑–¥–µ–ª—ã
    duplicates = find_duplicate_sections(data)
    
    if not duplicates:
        print("‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        return None
    
    print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(duplicates)} –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤:")
    
    for section_name, occurrences in duplicates.items():
        print(f"\nüîÑ –†–∞–∑–¥–µ–ª '{section_name}' –¥—É–±–ª–∏—Ä—É–µ—Ç—Å—è {len(occurrences)} —Ä–∞–∑:")
        for i, (path, content) in enumerate(occurrences, 1):
            print(f"   {i}. –ü—É—Ç—å: {path}")
            print(f"      –ö–ª—é—á–µ–π –≤ —Ä–∞–∑–¥–µ–ª–µ: {len(content) if isinstance(content, dict) else '–Ω–µ —Å–ª–æ–≤–∞—Ä—å'}")
            if isinstance(content, dict) and len(content) <= 5:
                print(f"      –ö–ª—é—á–∏: {list(content.keys())}")
            elif isinstance(content, dict):
                print(f"      –ü–µ—Ä–≤—ã–µ 5 –∫–ª—é—á–µ–π: {list(content.keys())[:5]}...")
    
    return duplicates

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –≤ —Ñ–∞–π–ª–∞—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤")
    print("=" * 60)
    
    # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
    locales_dir = Path("../src/locales")
    if not locales_dir.exists():
        locales_dir = Path("src/locales")
    if not locales_dir.exists():
        locales_dir = Path("locales")
    
    if not locales_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    print(f"üìÇ –ü–∞–ø–∫–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏: {locales_dir.absolute()}")
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    translation_files = []
    for lang_dir in locales_dir.iterdir():
        if lang_dir.is_dir():
            translation_file = lang_dir / "translation.json"
            if translation_file.exists():
                translation_files.append(translation_file)
    
    if not translation_files:
        print("‚ùå –§–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return
    
    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {len(translation_files)}")
    for file in translation_files:
        print(f"   - {file}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    all_duplicates = {}
    for file_path in translation_files:
        duplicates = analyze_file(file_path)
        if duplicates:
            all_duplicates[str(file_path)] = duplicates
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 60)
    
    if not all_duplicates:
        print("‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ!")
    else:
        print(f"‚ö†Ô∏è  –§–∞–π–ª–æ–≤ —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏: {len(all_duplicates)}")
        for file_path, duplicates in all_duplicates.items():
            print(f"\nüìÅ {file_path}:")
            for section_name, occurrences in duplicates.items():
                print(f"   üîÑ '{section_name}' - {len(occurrences)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    
    return all_duplicates

if __name__ == "__main__":
    main()
