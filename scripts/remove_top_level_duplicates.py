#!/usr/bin/env python3
"""
–£–º–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è.
–ò—â–µ—Ç –∏ —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ä–∞–∑–¥–µ–ª—ã (–∫–ª—é—á–∏ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è) –≤ JSON.
"""

import json
import os
from pathlib import Path
from collections import defaultdict
import shutil
import sys

def find_top_level_duplicates(json_data):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ä–∞–∑–¥–µ–ª—ã –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è
    """
    if not isinstance(json_data, dict):
        return []
    
    # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞
    key_counts = defaultdict(int)
    key_positions = defaultdict(list)
    
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ –∫–ª—é—á–µ–π
    keys_order = []
    position = 0
    
    for key in json_data.keys():
        key_counts[key] += 1
        key_positions[key].append(position)
        keys_order.append(key)
        position += 1
    
    # –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    duplicates = []
    for key, count in key_counts.items():
        if count > 1:
            duplicates.append({
                'key': key,
                'count': count,
                'positions': key_positions[key],
                'values': [json_data[key] for _ in range(count)]  # –î–ª—è –∞–Ω–∞–ª–∏–∑–∞
            })
    
    return duplicates

def analyze_duplicates(duplicates, data):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–∏–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å
    """
    removal_plan = []
    
    for dup in duplicates:
        key = dup['key']
        count = dup['count']
        
        print(f"\nüîÑ –ù–∞–π–¥–µ–Ω –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª '{key}' ({count} —Ä–∞–∑)")
        
        # –í Python —Å–ª–æ–≤–∞—Ä—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –≤—Å—Ç–∞–≤–∫–∏
        # –ù–∞–º –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ
        removal_plan.append({
            'key': key,
            'keep_first': True,
            'remove_count': count - 1
        })
        
        print(f"   ‚úÖ –ë—É–¥–µ–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å: –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ")
        print(f"   ‚ùå –ë—É–¥–µ–º —É–¥–∞–ª—è—Ç—å: {count - 1} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    
    return removal_plan

def remove_duplicate_keys(data, removal_plan):
    """
    –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –∫–ª—é—á–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
    """
    if not removal_plan:
        return data
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏
    new_data = {}
    seen_keys = set()
    
    for key, value in data.items():
        if key not in seen_keys:
            new_data[key] = value
            seen_keys.add(key)
            print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Ä–∞–∑–¥–µ–ª: {key}")
        else:
            print(f"  ‚ùå –£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: {key}")
    
    return new_data

def validate_json_structure(data):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–∞–ª–∏–¥–Ω–∞ –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    """
    try:
        json.dumps(data, ensure_ascii=False)
        return True, "OK"
    except Exception as e:
        return False, str(e)

def process_file(file_path, dry_run=False):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    """
    print(f"\nüìÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            original_data = json.load(f)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return False
    
    # –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è
    duplicates = find_top_level_duplicates(original_data)
    
    if not duplicates:
        print("‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        return True
    
    print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤: {len(duplicates)}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    removal_plan = analyze_duplicates(duplicates, original_data)
    
    if dry_run:
        print("\nüîç –†–ï–ñ–ò–ú –ü–†–û–°–ú–û–¢–†–ê - –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è")
        return True
    
    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï! –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ {sum(plan['remove_count'] for plan in removal_plan)} –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤.")
    response = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): ").lower().strip()
    if response not in ['y', 'yes', '–¥–∞']:
        print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return False
    
    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
    backup_path = f"{file_path}.backup"
    shutil.copy2(file_path, backup_path)
    print(f"üíæ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_path}")
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    print("\nüßπ –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ä–∞–∑–¥–µ–ª—ã:")
    cleaned_data = remove_duplicate_keys(original_data, removal_plan)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
    is_valid, validation_message = validate_json_structure(cleaned_data)
    if not is_valid:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ JSON: {validation_message}")
        return False
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω: {file_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ–±—Ä–∞—Ç–Ω–æ
        with open(file_path, 'r', encoding='utf-8') as f:
            test_data = json.load(f)
        
        original_sections = len(original_data)
        new_sections = len(cleaned_data)
        removed_sections = original_sections - new_sections
        
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   - –ë—ã–ª–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {original_sections}")
        print(f"   - –°—Ç–∞–ª–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {new_sections}")
        print(f"   - –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {removed_sections}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
        shutil.copy2(backup_path, file_path)
        print("üîÑ –§–∞–π–ª –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üßπ –£–î–ê–õ–ï–ù–ò–ï –î–£–ë–õ–ò–†–£–Æ–©–ò–•–°–Ø –†–ê–ó–î–ï–õ–û–í –í–ï–†–•–ù–ï–ì–û –£–†–û–í–ù–Ø")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    dry_run = "--dry-run" in sys.argv or "-d" in sys.argv
    if dry_run:
        print("üîç –†–ï–ñ–ò–ú –ü–†–û–°–ú–û–¢–†–ê - –Ω–∏–∫–∞–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ")
        print("=" * 60)
    
    # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
    locales_dir = Path("../src/locales")
    if not locales_dir.exists():
        locales_dir = Path("src/locales")
    if not locales_dir.exists():
        locales_dir = Path("locales")
    
    if not locales_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return 1
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    translation_files = []
    for lang_dir in locales_dir.iterdir():
        if lang_dir.is_dir():
            translation_file = lang_dir / "translation.json"
            if translation_file.exists():
                translation_files.append(translation_file)
    
    if not translation_files:
        print("‚ùå –§–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return 1
    
    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {len(translation_files)}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    success_count = 0
    for file_path in translation_files:
        if process_file(file_path, dry_run):
            success_count += 1
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 60)
    
    if success_count == len(translation_files):
        if dry_run:
            print("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")
            print("üí° –î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–µ–∑ --dry-run")
        else:
            print("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
            print("üíæ –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .backup")
    else:
        print(f"‚ö†Ô∏è  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ: {success_count}/{len(translation_files)}")
    
    return 0 if success_count == len(translation_files) else 1

if __name__ == "__main__":
    exit(main())
