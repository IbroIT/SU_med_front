#!/usr/bin/env python3
"""
–ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –≤ JSON —Ñ–∞–π–ª–µ –∫–∞–∫ –≤ —Ç–µ–∫—Å—Ç–µ.
–ò—â–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –∫–ª—é—á–∏ –¥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON.
"""

import re
import json
from pathlib import Path
from collections import defaultdict

def find_json_sections_in_text(text):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ä–∞–∑–¥–µ–ª—ã (–∫–ª—é—á–∏ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è) –≤ —Ç–µ–∫—Å—Ç–µ JSON
    """
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–π –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è
    # –ò—â–µ–º "–∫–ª—é—á": { –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ (—Å —É—á–µ—Ç–æ–º –ø—Ä–æ–±–µ–ª–æ–≤)
    pattern = r'^\s*"([^"]+)"\s*:\s*\{'
    
    sections = []
    lines = text.split('\n')
    
    for line_num, line in enumerate(lines, 1):
        match = re.match(pattern, line)
        if match:
            key = match.group(1)
            sections.append({
                'key': key,
                'line': line_num,
                'text': line.strip()
            })
    
    return sections

def analyze_text_duplicates(sections):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
    """
    key_counts = defaultdict(list)
    
    for section in sections:
        key_counts[section['key']].append(section)
    
    duplicates = {}
    for key, occurrences in key_counts.items():
        if len(occurrences) > 1:
            duplicates[key] = occurrences
    
    return duplicates

def analyze_file(file_path):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    """
    print(f"\nüìÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return False
    
    # –ù–∞—Ö–æ–¥–∏–º —Ä–∞–∑–¥–µ–ª—ã –≤ —Ç–µ–∫—Å—Ç–µ
    sections = find_json_sections_in_text(content)
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(sections)}")
    
    # –ò—â–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    duplicates = analyze_text_duplicates(sections)
    
    if not duplicates:
        print("‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        return True
    
    print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∫–ª—é—á–µ–π: {len(duplicates)}")
    
    for key, occurrences in duplicates.items():
        print(f"\nüîÑ –ö–ª—é—á '{key}' –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è {len(occurrences)} —Ä–∞–∑:")
        for i, occurrence in enumerate(occurrences, 1):
            print(f"   {i}. –°—Ç—Ä–æ–∫–∞ {occurrence['line']}: {occurrence['text']}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ JSON
    try:
        parsed_data = json.loads(content)
        print(f"\nüìä –ü–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Å—Ç–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–æ–≤: {len(parsed_data)}")
        print("üí° Python –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ, –æ—Å—Ç–∞–≤–ª—è—è –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
    
    return duplicates

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ü–û–ò–°–ö –î–£–ë–õ–ò–ö–ê–¢–û–í –í –¢–ï–ö–°–¢–ï JSON")
    print("=" * 50)
    
    # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
    locales_dir = Path("../src/locales")
    if not locales_dir.exists():
        locales_dir = Path("src/locales")
    
    if not locales_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    translation_files = []
    for lang_dir in locales_dir.iterdir():
        if lang_dir.is_dir():
            translation_file = lang_dir / "translation.json"
            if translation_file.exists():
                translation_files.append(translation_file)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    total_duplicates = {}
    for file_path in translation_files:
        duplicates = analyze_file(file_path)
        if duplicates:
            total_duplicates[str(file_path)] = duplicates
    
    print("\n" + "=" * 50)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 50)
    
    if total_duplicates:
        print(f"‚ö†Ô∏è  –§–∞–π–ª–æ–≤ —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏: {len(total_duplicates)}")
        for file_path, duplicates in total_duplicates.items():
            print(f"\nüìÅ {file_path}:")
            for key, occurrences in duplicates.items():
                lines = [str(occ['line']) for occ in occurrences]
                print(f"   üîÑ '{key}' –Ω–∞ —Å—Ç—Ä–æ–∫–∞—Ö: {', '.join(lines)}")
    else:
        print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")

if __name__ == "__main__":
    main()
