#!/usr/bin/env python3
"""
–§–ò–ù–ê–õ–¨–ù–´–ô –°–ö–†–ò–ü–¢: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤.
–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –Ω–∞–π–¥–µ—Ç –∏ —É–¥–∞–ª–∏—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ä–∞–∑–¥–µ–ª—ã –≤ JSON —Ñ–∞–π–ª–∞—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤,
—Å–æ—Ö—Ä–∞–Ω—è—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞.
"""

import re
import json
import shutil
from pathlib import Path
from collections import defaultdict
import sys

def find_json_sections_in_text(text):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ä–∞–∑–¥–µ–ª—ã (–∫–ª—é—á–∏ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è) –≤ —Ç–µ–∫—Å—Ç–µ JSON
    """
    pattern = r'^\s*"([^"]+)"\s*:\s*\{'
    sections = []
    lines = text.split('\n')
    
    for line_num, line in enumerate(lines, 1):
        match = re.match(pattern, line)
        if match:
            key = match.group(1)
            sections.append({
                'key': key,
                'line': line_num,
                'text': line.strip(),
                'original_line': line
            })
    
    return sections

def find_duplicates(sections):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ä–∞–∑–¥–µ–ª—ã
    """
    key_counts = defaultdict(list)
    
    for section in sections:
        key_counts[section['key']].append(section)
    
    duplicates = {}
    for key, occurrences in key_counts.items():
        if len(occurrences) > 1:
            duplicates[key] = occurrences
    
    return duplicates

def remove_duplicates_from_text(text, duplicates):
    """
    –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ä–∞–∑–¥–µ–ª—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
    """
    lines = text.split('\n')
    lines_to_remove = set()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    for key, occurrences in duplicates.items():
        # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ, —É–¥–∞–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
        keep_first = occurrences[0]
        remove_sections = occurrences[1:]
        
        print(f"  üîÑ –ö–ª—é—á '{key}':")
        print(f"     ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º: —Å—Ç—Ä–æ–∫–∞ {keep_first['line']}")
        
        for section in remove_sections:
            print(f"     ‚ùå –£–¥–∞–ª—è–µ–º: —Å—Ç—Ä–æ–∫–∞ {section['line']}")
            # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü —Ä–∞–∑–¥–µ–ª–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            start_line = section['line'] - 1  # -1 –ø–æ—Ç–æ–º—É —á—Ç–æ –Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 1
            end_line = find_section_end(lines, start_line)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Ä–∞–∑–¥–µ–ª–∞ –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            for i in range(start_line, end_line + 1):
                lines_to_remove.add(i)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏
    cleaned_lines = []
    for i, line in enumerate(lines):
        if i not in lines_to_remove:
            cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines)

def find_section_end(lines, start_line):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –∫–æ–Ω–µ—Ü JSON —Ä–∞–∑–¥–µ–ª–∞, –Ω–∞—á–∏–Ω–∞—é—â–µ–≥–æ—Å—è —Å start_line
    """
    if start_line >= len(lines):
        return start_line
    
    # –°—á–∏—Ç–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ —Å–∫–æ–±–æ–∫
    brace_count = 0
    in_section = False
    
    for i in range(start_line, len(lines)):
        line = lines[i]
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å—á–∏—Ç–∞—Ç—å —Å–∫–æ–±–∫–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏ —Ä–∞–∑–¥–µ–ª–∞
        if '{' in line and not in_section:
            in_section = True
        
        if in_section:
            # –°—á–∏—Ç–∞–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–µ –∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Å–∫–æ–±–∫–∏
            brace_count += line.count('{')
            brace_count -= line.count('}')
            
            # –ï—Å–ª–∏ —Å–∫–æ–±–∫–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã, –∑–Ω–∞—á–∏—Ç —Ä–∞–∑–¥–µ–ª –∑–∞–∫–æ–Ω—á–∏–ª—Å—è
            if brace_count == 0:
                return i
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∫–æ–Ω–µ—Ü, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É
    return len(lines) - 1

def validate_json_text(text):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —Ç–µ–∫—Å—Ç —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON
    """
    try:
        json.loads(text)
        return True, "OK"
    except json.JSONDecodeError as e:
        return False, f"JSON Error: {e}"
    except Exception as e:
        return False, f"Error: {e}"

def process_file(file_path, dry_run=False):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    """
    print(f"\nüìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {file_path}")
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            original_text = f.read()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return False
    
    # –ù–∞—Ö–æ–¥–∏–º —Ä–∞–∑–¥–µ–ª—ã
    sections = find_json_sections_in_text(original_text)
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(sections)}")
    
    # –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    duplicates = find_duplicates(sections)
    
    if not duplicates:
        print("‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        return True
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    total_duplicates = sum(len(occurrences) - 1 for occurrences in duplicates.values())
    print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(duplicates)} –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∫–ª—é—á–µ–π")
    print(f"‚ö†Ô∏è  –í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: {total_duplicates}")
    
    if dry_run:
        print("\nüîç –†–ï–ñ–ò–ú –ü–†–û–°–ú–û–¢–†–ê:")
        for key, occurrences in duplicates.items():
            keep = occurrences[0]
            remove = occurrences[1:]
            print(f"  üîÑ '{key}': —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç—Ä–æ–∫—É {keep['line']}, —É–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ {[s['line'] for s in remove]}")
        return True
    
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï! –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ {total_duplicates} –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ä–∞–∑–¥–µ–ª–æ–≤ –∏–∑ {len(duplicates)} –∫–ª—é—á–µ–π.")
    response = input("‚ùì –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ? (y/N): ").lower().strip()
    if response not in ['y', 'yes', '–¥–∞', '–¥']:
        print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return False
    
    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
    backup_path = f"{file_path}.backup.{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}"
    try:
        shutil.copy2(file_path, backup_path)
        print(f"üíæ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_path}")
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é: {e}")
        return False
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    print("\nüßπ –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã:")
    try:
        cleaned_text = remove_duplicates_from_text(original_text, duplicates)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å JSON
    is_valid, validation_error = validate_json_text(cleaned_text)
    if not is_valid:
        print(f"‚ùå –ü–æ–ª—É—á–µ–Ω –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON: {validation_error}")
        print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        return False
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(cleaned_text)
        print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å JSON
        test_data = json.loads(cleaned_text)
        new_section_count = len(test_data)
        original_section_count = len(sections)
        
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
        print(f"   - –ë—ã–ª–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {original_section_count}")
        print(f"   - –°—Ç–∞–ª–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {new_section_count}")
        print(f"   - –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {original_section_count - new_section_count}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        # –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
        try:
            shutil.copy2(backup_path, file_path)
            print("üîÑ –§–∞–π–ª –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
        except:
            print("üí• –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ñ–∞–π–ª!")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üßπ –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ß–ò–°–¢–ö–ê –î–£–ë–õ–ò–†–£–Æ–©–ò–•–°–Ø –†–ê–ó–î–ï–õ–û–í")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    dry_run = "--dry-run" in sys.argv or "-d" in sys.argv
    if dry_run:
        print("üîç –†–ï–ñ–ò–ú –ü–†–û–°–ú–û–¢–†–ê - –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è")
        print("=" * 60)
    
    # –ù–∞—Ö–æ–¥–∏–º –ø–∞–ø–∫—É —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
    locales_dir = Path("../src/locales")
    if not locales_dir.exists():
        locales_dir = Path("src/locales")
    
    if not locales_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return 1
    
    # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    translation_files = []
    for lang_dir in locales_dir.iterdir():
        if lang_dir.is_dir():
            translation_file = lang_dir / "translation.json"
            if translation_file.exists():
                translation_files.append(translation_file)
    
    if not translation_files:
        print("‚ùå –§–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return 1
    
    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(translation_files)}")
    for f in translation_files:
        print(f"   - {f}")
    
    if not dry_run:
        print(f"\nüí° –°–æ–≤–µ—Ç: —Å–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å —Ñ–ª–∞–≥–æ–º --dry-run –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞")
        response = input("‚ùì –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–æ–≤? (y/N): ").lower().strip()
        if response not in ['y', 'yes', '–¥–∞', '–¥']:
            print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
            return 0
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
    success_count = 0
    for file_path in translation_files:
        if process_file(file_path, dry_run):
            success_count += 1
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 60)
    
    if success_count == len(translation_files):
        print("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
        if not dry_run:
            print("üíæ –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
            print("üî• –î—É–±–ª–∏–∫–∞—Ç—ã —É–¥–∞–ª–µ–Ω—ã!")
            print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
            print("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞")  
            print("   2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç—ã")
            print("   3. –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ —Å–ª–æ–º–∞–ª–æ—Å—å, –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏–∑ .backup —Ñ–∞–π–ª–æ–≤")
    else:
        print(f"‚ö†Ô∏è  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {success_count}/{len(translation_files)}")
    
    return 0 if success_count == len(translation_files) else 1

# –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç pandas —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω
try:
    import pandas as pd
except ImportError:
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –¥–ª—è timestamp
    class pd:
        class Timestamp:
            @staticmethod
            def now():
                from datetime import datetime
                return datetime.now()

if __name__ == "__main__":
    exit(main())
